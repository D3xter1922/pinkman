{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "from scipy.stats import norm\n",
    "numpy.seterr(all='ignore')\n",
    "\n",
    "def pdf(x,mu,sigma): #normal distribution pdf\n",
    "    x = (x-mu)/sigma\n",
    "    return numpy.exp(-x**2/2)/(numpy.sqrt(2*numpy.pi)*sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invLogCDF(x,mu,sigma): #normal distribution cdf\n",
    "    x = (x - mu) / sigma\n",
    "    return norm.logcdf(-x) #note: we mutiple by -1 after normalization to better get the 1-cdf\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1 + numpy.exp(-x))\n",
    "\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return x * (1. - x)\n",
    "\n",
    "def tanh(x):\n",
    "    return numpy.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1. - x * x\n",
    "\n",
    "def softmax(x):\n",
    "    e = numpy.exp(x - numpy.max(x))  # prevent overflow\n",
    "    if e.ndim == 1:\n",
    "        return e / numpy.sum(e, axis=0)\n",
    "    else:  \n",
    "        return e / numpy.array([numpy.sum(e, axis=1)]).T  # ndim = 2\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def dReLU(x):\n",
    "    return 1. * (x > 0)\n",
    "\n",
    "class rollmean:\n",
    "    def __init__(self,k):\n",
    "        self.winsize = k\n",
    "        self.window = numpy.zeros(self.winsize)\n",
    "        self.pointer = 0\n",
    "\n",
    "    def apply(self,newval):\n",
    "        self.window[self.pointer]=newval\n",
    "        self.pointer = (self.pointer+1) % self.winsize\n",
    "        return numpy.mean(self.window)\n",
    "\n",
    "# probability density for the Gaussian dist\n",
    "# def gaussian(x, mean=0.0, scale=1.0):\n",
    "#     s = 2 * numpy.power(scale, 2)\n",
    "#     e = numpy.exp( - numpy.power((x - mean), 2) / s )\n",
    "\n",
    "#     return e / numpy.square(numpy.pi * s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, to_tree\n",
    "\n",
    "# A helper class for KitNET which performs a correlation-based incremental clustering of the dimensions in X\n",
    "# n: the number of dimensions in the dataset\n",
    "# For more information and citation, please see our NDSS'18 paper: Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection\n",
    "class corClust:\n",
    "    def __init__(self,n):\n",
    "        #parameter:\n",
    "        self.n = n\n",
    "        #varaibles\n",
    "        self.c = np.zeros(n) #linear num of features\n",
    "        self.c_r = np.zeros(n) #linear sum of feature residules\n",
    "        self.c_rs = np.zeros(n) #linear sum of feature residules\n",
    "        self.C = np.zeros((n,n)) #partial correlation matrix\n",
    "        self.N = 0 #number of updates performed\n",
    "\n",
    "    # x: a numpy vector of length n\n",
    "    def update(self,x):\n",
    "        self.N += 1\n",
    "        self.c += x\n",
    "        c_rt = x - self.c/self.N\n",
    "        self.c_r += c_rt\n",
    "        self.c_rs += c_rt**2\n",
    "        self.C += np.outer(c_rt,c_rt)\n",
    "\n",
    "    # creates the current correlation distance matrix between the features\n",
    "    def corrDist(self):\n",
    "        c_rs_sqrt = np.sqrt(self.c_rs)\n",
    "        C_rs_sqrt = np.outer(c_rs_sqrt,c_rs_sqrt)\n",
    "        C_rs_sqrt[C_rs_sqrt==0] = 1e-100 #this protects against dive by zero erros (occurs when a feature is a constant)\n",
    "        D = 1-self.C/C_rs_sqrt #the correlation distance matrix\n",
    "        D[D<0] = 0 #small negatives may appear due to the incremental fashion in which we update the mean. Therefore, we 'fix' them\n",
    "        return D\n",
    "\n",
    "    # clusters the features together, having no more than maxClust features per cluster\n",
    "    def cluster(self,maxClust):\n",
    "        D = self.corrDist()\n",
    "        Z = linkage(D[np.triu_indices(self.n, 1)])  # create a linkage matrix based on the distance matrix\n",
    "        if maxClust < 1:\n",
    "            maxClust = 1\n",
    "        if maxClust > self.n:\n",
    "            maxClust = self.n\n",
    "        map = self.__breakClust__(to_tree(Z),maxClust)\n",
    "        return map\n",
    "\n",
    "    # a recursive helper function which breaks down the dendrogram branches until all clusters have no more than maxClust elements\n",
    "    def __breakClust__(self,dendro,maxClust):\n",
    "        if dendro.count <= maxClust: #base case: we found a minimal cluster, so mark it\n",
    "            return [dendro.pre_order()] #return the origional ids of the features in this cluster\n",
    "        return self.__breakClust__(dendro.get_left(),maxClust) + self.__breakClust__(dendro.get_right(),maxClust)\n",
    "\n",
    "# Copyright (c) 2017 Yisroel Mirsky\n",
    "#\n",
    "# MIT License\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining\n",
    "# a copy of this software and associated documentation files (the\n",
    "# \"Software\"), to deal in the Software without restriction, including\n",
    "# without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software, and to\n",
    "# permit persons to whom the Software is furnished to do so, subject to\n",
    "# the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be\n",
    "# included in all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017 Yusuke Sugomori\n",
    "#\n",
    "# MIT License\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining\n",
    "# a copy of this software and associated documentation files (the\n",
    "# \"Software\"), to deal in the Software without restriction, including\n",
    "# without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software, and to\n",
    "# permit persons to whom the Software is furnished to do so, subject to\n",
    "# the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be\n",
    "# included in all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "# Portions of this code have been adapted from Yusuke Sugomori's code on GitHub: https://github.com/yusugomori/DeepLearning\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "import json\n",
    "\n",
    "class dA_params:\n",
    "    def __init__(self,n_visible = 5, n_hidden = 3, lr=0.001, corruption_level=0.0, gracePeriod = 10000, hiddenRatio=None):\n",
    "        self.n_visible = n_visible# num of units in visible (input) layer\n",
    "        self.n_hidden = n_hidden# num of units in hidden layer\n",
    "        self.lr = lr\n",
    "        self.corruption_level = corruption_level\n",
    "        self.gracePeriod = gracePeriod\n",
    "        self.hiddenRatio = hiddenRatio\n",
    "\n",
    "class dA:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "        if self.params.hiddenRatio is not None:\n",
    "            self.params.n_hidden = int(numpy.ceil(self.params.n_visible*self.params.hiddenRatio))\n",
    "\n",
    "        # for 0-1 normlaization\n",
    "        self.norm_max = numpy.ones((self.params.n_visible,)) * -numpy.Inf\n",
    "        self.norm_min = numpy.ones((self.params.n_visible,)) * numpy.Inf\n",
    "        self.n = 0\n",
    "\n",
    "        self.rng = numpy.random.RandomState(1234)\n",
    "\n",
    "        a = 1. / self.params.n_visible\n",
    "        self.W = numpy.array(self.rng.uniform(  # initialize W uniformly\n",
    "            low=-a,\n",
    "            high=a,\n",
    "            size=(self.params.n_visible, self.params.n_hidden)))\n",
    "\n",
    "        self.hbias = numpy.zeros(self.params.n_hidden)  # initialize h bias 0\n",
    "        self.vbias = numpy.zeros(self.params.n_visible)  # initialize v bias 0\n",
    "        self.W_prime = self.W.T\n",
    "\n",
    "\n",
    "    def get_corrupted_input(self, input, corruption_level):\n",
    "        assert corruption_level < 1\n",
    "\n",
    "        return self.rng.binomial(size=input.shape,\n",
    "                                 n=1,\n",
    "                                 p=1 - corruption_level) * input\n",
    "\n",
    "    # Encode\n",
    "    def get_hidden_values(self, input):\n",
    "        return sigmoid(numpy.dot(input, self.W) + self.hbias)\n",
    "\n",
    "    # Decode\n",
    "    def get_reconstructed_input(self, hidden):\n",
    "        return sigmoid(numpy.dot(hidden, self.W_prime) + self.vbias)\n",
    "\n",
    "    def train(self, x):\n",
    "        self.n = self.n + 1\n",
    "        # update norms\n",
    "        self.norm_max[x > self.norm_max] = x[x > self.norm_max]\n",
    "        self.norm_min[x < self.norm_min] = x[x < self.norm_min]\n",
    "\n",
    "        # 0-1 normalize\n",
    "        x = (x - self.norm_min) / (self.norm_max - self.norm_min + 0.0000000000000001)\n",
    "\n",
    "        if self.params.corruption_level > 0.0:\n",
    "            tilde_x = self.get_corrupted_input(x, self.params.corruption_level)\n",
    "        else:\n",
    "            tilde_x = x\n",
    "        y = self.get_hidden_values(tilde_x)\n",
    "        z = self.get_reconstructed_input(y)\n",
    "\n",
    "        L_h2 = x - z\n",
    "        L_h1 = numpy.dot(L_h2, self.W) * y * (1 - y)\n",
    "\n",
    "        L_vbias = L_h2\n",
    "        L_hbias = L_h1\n",
    "        L_W = numpy.outer(tilde_x.T, L_h1) + numpy.outer(L_h2.T, y)\n",
    "\n",
    "        self.W += self.params.lr * L_W\n",
    "        self.hbias += self.params.lr * numpy.mean(L_hbias, axis=0)\n",
    "        self.vbias += self.params.lr * numpy.mean(L_vbias, axis=0)\n",
    "        return numpy.sqrt(numpy.mean(L_h2**2)) #the RMSE reconstruction error during training\n",
    "\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "        y = self.get_hidden_values(x)\n",
    "        z = self.get_reconstructed_input(y)\n",
    "        return z\n",
    "\n",
    "    def execute(self, x): #returns MSE of the reconstruction of x\n",
    "        if self.n < self.params.gracePeriod:\n",
    "            return 0.0\n",
    "        else:\n",
    "            # 0-1 normalize\n",
    "            x = (x - self.norm_min) / (self.norm_max - self.norm_min + 0.0000000000000001)\n",
    "            z = self.reconstruct(x)\n",
    "            rmse = numpy.sqrt(((x - z) ** 2).mean()) #MSE\n",
    "            return rmse\n",
    "\n",
    "\n",
    "    def inGrace(self):\n",
    "        return self.n < self.params.gracePeriod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This class represents a KitNET machine learner.\n",
    "# KitNET is a lightweight online anomaly detection algorithm based on an ensemble of autoencoders.\n",
    "# For more information and citation, please see our NDSS'18 paper: Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection\n",
    "# For licensing information, see the end of this document\n",
    "\n",
    "class KitNET:\n",
    "    #n: the number of features in your input dataset (i.e., x \\in R^n)\n",
    "    #m: the maximum size of any autoencoder in the ensemble layer\n",
    "    #AD_grace_period: the number of instances the network will learn from before producing anomaly scores\n",
    "    #FM_grace_period: the number of instances which will be taken to learn the feature mapping. If 'None', then FM_grace_period=AM_grace_period\n",
    "    #learning_rate: the default stochastic gradient descent learning rate for all autoencoders in the KitNET instance.\n",
    "    #hidden_ratio: the default ratio of hidden to visible neurons. E.g., 0.75 will cause roughly a 25% compression in the hidden layer.\n",
    "    #feature_map: One may optionally provide a feature map instead of learning one. The map must be a list,\n",
    "    #           where the i-th entry contains a list of the feature indices to be assingned to the i-th autoencoder in the ensemble.\n",
    "    #           For example, [[2,5,3],[4,0,1],[6,7]]\n",
    "    def __init__(self,n,max_autoencoder_size=10,FM_grace_period=None,AD_grace_period=10000,learning_rate=0.1,hidden_ratio=0.75, feature_map = None):\n",
    "        # Parameters:\n",
    "        self.AD_grace_period = AD_grace_period\n",
    "        if FM_grace_period is None:\n",
    "            self.FM_grace_period = AD_grace_period\n",
    "        else:\n",
    "            self.FM_grace_period = FM_grace_period\n",
    "        if max_autoencoder_size <= 0:\n",
    "            self.m = 1\n",
    "        else:\n",
    "            self.m = max_autoencoder_size\n",
    "        self.lr = learning_rate\n",
    "        self.hr = hidden_ratio\n",
    "        self.n = n\n",
    "\n",
    "        # Variables\n",
    "        self.n_trained = 0 # the number of training instances so far\n",
    "        self.n_executed = 0 # the number of executed instances so far\n",
    "        self.v = feature_map\n",
    "        if self.v is None:\n",
    "            print(\"Feature-Mapper: train-mode, Anomaly-Detector: off-mode\")\n",
    "        else:\n",
    "            self.__createAD__()\n",
    "            print(\"Feature-Mapper: execute-mode, Anomaly-Detector: train-mode\")\n",
    "        self.FM = corClust(self.n) #incremental feature cluatering for the feature mapping process\n",
    "        self.ensembleLayer = []\n",
    "        self.outputLayer = None\n",
    "\n",
    "    #If FM_grace_period+AM_grace_period has passed, then this function executes KitNET on x. Otherwise, this function learns from x.\n",
    "    #x: a numpy array of length n\n",
    "    #Note: KitNET automatically performs 0-1 normalization on all attributes.\n",
    "    def process(self,x):\n",
    "        if self.n_trained > self.FM_grace_period + self.AD_grace_period: #If both the FM and AD are in execute-mode\n",
    "            return self.execute(x)\n",
    "        else:\n",
    "            self.train(x)\n",
    "            return 0.0\n",
    "\n",
    "    #force train KitNET on x\n",
    "    #returns the anomaly score of x during training (do not use for alerting)\n",
    "    def train(self,x):\n",
    "        if self.n_trained <= self.FM_grace_period and self.v is None: #If the FM is in train-mode, and the user has not supplied a feature mapping\n",
    "            #update the incremetnal correlation matrix\n",
    "            self.FM.update(x)\n",
    "            if self.n_trained == self.FM_grace_period: #If the feature mapping should be instantiated\n",
    "                self.v = self.FM.cluster(self.m)\n",
    "                self.__createAD__()\n",
    "                print(\"The Feature-Mapper found a mapping: \"+str(self.n)+\" features to \"+str(len(self.v))+\" autoencoders.\")\n",
    "                print(\"Feature-Mapper: execute-mode, Anomaly-Detector: train-mode\")\n",
    "        else: #train\n",
    "            ## Ensemble Layer\n",
    "            S_l1 = np.zeros(len(self.ensembleLayer))\n",
    "            for a in range(len(self.ensembleLayer)):\n",
    "                # make sub instance for autoencoder 'a'\n",
    "                xi = x[self.v[a]]\n",
    "                S_l1[a] = self.ensembleLayer[a].train(xi)\n",
    "            ## OutputLayer\n",
    "            self.outputLayer.train(S_l1)\n",
    "            if self.n_trained == self.AD_grace_period+self.FM_grace_period:\n",
    "                print(\"Feature-Mapper: execute-mode, Anomaly-Detector: exeute-mode\")\n",
    "        self.n_trained += 1\n",
    "\n",
    "    #force execute KitNET on x\n",
    "    def execute(self,x):\n",
    "        if self.v is None:\n",
    "            raise RuntimeError('KitNET Cannot execute x, because a feature mapping has not yet been learned or provided. Try running process(x) instead.')\n",
    "        else:\n",
    "            self.n_executed += 1\n",
    "            ## Ensemble Layer\n",
    "            S_l1 = np.zeros(len(self.ensembleLayer))\n",
    "            for a in range(len(self.ensembleLayer)):\n",
    "                # make sub inst\n",
    "                xi = x[self.v[a]]\n",
    "                S_l1[a] = self.ensembleLayer[a].execute(xi)\n",
    "            ## OutputLayer\n",
    "            return self.outputLayer.execute(S_l1)\n",
    "\n",
    "    def __createAD__(self):\n",
    "        # construct ensemble layer\n",
    "        for map in self.v:\n",
    "            params = dA_params(n_visible=len(map), n_hidden=0, lr=self.lr, corruption_level=0, gracePeriod=0, hiddenRatio=self.hr)\n",
    "            self.ensembleLayer.append(dA(params))\n",
    "\n",
    "        # construct output layer\n",
    "        params = dA_params(len(self.v), n_hidden=0, lr=self.lr, corruption_level=0, gracePeriod=0, hiddenRatio=self.hr)\n",
    "        self.outputLayer = dA(params)\n",
    "\n",
    "# Copyright (c) 2017 Yisroel Mirsky\n",
    "#\n",
    "# MIT License\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining\n",
    "# a copy of this software and associated documentation files (the\n",
    "# \"Software\"), to deal in the Software without restriction, including\n",
    "# without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software, and to\n",
    "# permit persons to whom the Software is furnished to do so, subject to\n",
    "# the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be\n",
    "# included in all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    "# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    "# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    "# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    "# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping Sample Dataset...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print(\"Unzipping Sample Dataset...\")\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"dataset.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Sample dataset...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Reading Sample dataset...\")\n",
    "X = pd.read_csv(\"mirai3.csv\",header=None).to_numpy() #an m-by-n dataset with m observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.89742, 68.1526 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Mapper: train-mode, Anomaly-Detector: off-mode\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KitNET params:\n",
    "maxAE = 10 #maximum size for any autoencoder in the ensemble layer\n",
    "FMgrace = 5000 #the number of instances taken to learn the feature mapping (the ensemble's architecture)\n",
    "ADgrace = 50000 #the number of instances used to train the anomaly detector (ensemble itself)\n",
    "\n",
    "# Build KitNET\n",
    "K = KitNET(X.shape[1],maxAE,FMgrace,ADgrace)\n",
    "RMSEs = np.zeros(X.shape[0]) # a place to save the scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KitNET:\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "The Feature-Mapper found a mapping: 2 features to 1 autoencoders.\n",
      "Feature-Mapper: execute-mode, Anomaly-Detector: train-mode\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "Feature-Mapper: execute-mode, Anomaly-Detector: exeute-mode\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "Complete. Time elapsed: 13.226577043533325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Running KitNET:\")\n",
    "start = time.time()\n",
    "# Here we process (train/execute) each individual observation.\n",
    "# In this way, X is essentially a stream, and each observation is discarded after performing process() method.\n",
    "for i in range(X.shape[0]):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    RMSEs[i] = K.process(X[i,]) #will train during the grace periods, then execute on all the rest.\n",
    "stop = time.time()\n",
    "print(\"Complete. Time elapsed: \"+ str(stop - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here we demonstrate how one can fit the RMSE scores to a log-normal distribution (useful for finding/setting a cutoff threshold \\phi)\n",
    "from scipy.stats import norm\n",
    "benignSample = np.log(RMSEs[FMgrace+ADgrace+1:71000])\n",
    "logProbs = norm.logsf(np.log(RMSEs), np.mean(benignSample), np.std(benignSample))\n",
    "\n",
    "# plot the RMSE anomaly scores\n",
    "print(\"Plotting results\")\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "plt.figure(figsize=(10,5))\n",
    "timestamps = pd.read_csv(\"mirai3_ts.csv\",header=None).as_matrix()\n",
    "fig = plt.scatter(timestamps[FMgrace+ADgrace+1:],RMSEs[FMgrace+ADgrace+1:],s=0.1,c=logProbs[FMgrace+ADgrace+1:],cmap='RdYlGn')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Anomaly Scores from KitNET's Execution Phase\")\n",
    "plt.ylabel(\"RMSE (log scaled)\")\n",
    "plt.xlabel(\"Time elapsed [min]\")\n",
    "plt.annotate('Mirai C&C channel opened [Telnet]', xy=(timestamps[71662],RMSEs[71662]), xytext=(timestamps[58000],1),arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "plt.annotate('Mirai Bot Activated\\nMirai scans network for vulnerable devices', xy=(timestamps[72662],1), xytext=(timestamps[55000],5),arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "figbar=plt.colorbar()\n",
    "figbar.ax.set_ylabel('Log Probability\\n ', rotation=270)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinkmanVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
